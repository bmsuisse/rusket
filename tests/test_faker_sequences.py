"""Tests using Faker-generated event-log data for sequential-pattern mining.

Covers PrefixSpan, sequences_from_event_log, and customer_saturation analytics
with realistic user/timestamp/product data generated by Faker.
"""

from __future__ import annotations

import pandas as pd
import pytest
from faker import Faker

SEED = 42


# ---------------------------------------------------------------------------
# Faker data generators
# ---------------------------------------------------------------------------


def _make_event_log(
    n_users: int = 50,
    events_per_user_range: tuple[int, int] = (3, 12),
    n_products: int = 30,
    seed: int = SEED,
) -> pd.DataFrame:
    """Generate a realistic event log with Faker users, timestamps, and products."""
    fake = Faker()
    Faker.seed(seed)

    import numpy as np

    rng = np.random.default_rng(seed)

    products: list[str] = []
    seen: set[str] = set()
    while len(products) < n_products:
        name = f"{fake.word().capitalize()} {fake.color_name()}"
        if name not in seen:
            seen.add(name)
            products.append(name)

    rows: list[dict[str, object]] = []
    for _ in range(n_users):
        user = fake.user_name()
        n_events = rng.integers(*events_per_user_range)
        # Generate sorted timestamps
        timestamps = sorted(fake.date_time_between(start_date="-1y", end_date="now") for _ in range(n_events))
        for ts in timestamps:
            rows.append({"user": user, "timestamp": ts, "product": rng.choice(products)})

    return pd.DataFrame(rows)


def _make_purchase_log(
    n_customers: int = 60,
    n_categories: int = 15,
    purchases_per_customer: tuple[int, int] = (1, 10),
    seed: int = SEED,
) -> pd.DataFrame:
    """Generate customer purchase data for saturation analytics."""
    fake = Faker()
    Faker.seed(seed)

    import numpy as np

    rng = np.random.default_rng(seed)

    categories = [fake.word().capitalize() for _ in range(n_categories)]

    rows: list[dict[str, object]] = []
    for _ in range(n_customers):
        customer = fake.name()
        n_buys = rng.integers(*purchases_per_customer)
        for _ in range(n_buys):
            rows.append({"customer": customer, "category": rng.choice(categories)})

    return pd.DataFrame(rows)


# ---------------------------------------------------------------------------
# PrefixSpan with Faker event logs
# ---------------------------------------------------------------------------


class TestFakerPrefixSpan:
    """PrefixSpan sequential pattern mining on Faker-generated event logs."""

    def test_sequences_from_event_log_pandas(self) -> None:
        from rusket.prefixspan import sequences_from_event_log

        df = _make_event_log(n_users=30, n_products=15)
        seqs, mapping = sequences_from_event_log(df, "user", "timestamp", "product")

        # indptr should have n_users + 1 entries
        assert len(seqs[0]) > 1
        # Total events
        assert len(seqs[1]) == len(df)
        # Mapping should map to product names
        assert len(mapping) > 0

    def test_sequences_from_event_log_polars(self) -> None:
        pl = pytest.importorskip("polars")
        from rusket.prefixspan import sequences_from_event_log

        df = _make_event_log(n_users=20, n_products=10, seed=99)
        df_pl = pl.from_pandas(df)
        seqs, mapping = sequences_from_event_log(df_pl, "user", "timestamp", "product")
        assert len(seqs[0]) > 1
        assert len(mapping) > 0

    def test_prefixspan_mine(self) -> None:
        from rusket.prefixspan import PrefixSpan, sequences_from_event_log

        df = _make_event_log(n_users=40, n_products=10, seed=77)
        seqs, mapping = sequences_from_event_log(df, "user", "timestamp", "product")

        result = PrefixSpan(seqs, min_support=3).mine()
        assert isinstance(result, pd.DataFrame)
        assert len(result) > 0
        assert "sequence" in result.columns
        assert "support" in result.columns

    def test_prefixspan_high_support_subset(self) -> None:
        from rusket.prefixspan import PrefixSpan, sequences_from_event_log

        df = _make_event_log(n_users=50, n_products=8, seed=33)
        seqs, _ = sequences_from_event_log(df, "user", "timestamp", "product")

        low = PrefixSpan(seqs, min_support=2).mine()
        high = PrefixSpan(seqs, min_support=5).mine()
        # Higher support should find fewer or equal patterns
        assert len(high) <= len(low)


# ---------------------------------------------------------------------------
# Customer saturation analytics with Faker data
# ---------------------------------------------------------------------------


class TestFakerAnalytics:
    """customer_saturation with Faker-generated purchase data."""

    def test_saturation_basic(self) -> None:
        from rusket.analytics import customer_saturation

        df = _make_purchase_log(n_customers=40, n_categories=10)
        sat = customer_saturation(df, user_col="customer", category_col="category")

        assert isinstance(sat, pd.DataFrame)
        assert len(sat) > 0
        assert "unique_count" in sat.columns
        assert "saturation_pct" in sat.columns
        assert "decile" in sat.columns

        # Saturation percentage must be in [0, 1]
        assert (sat["saturation_pct"] >= 0).all()
        assert (sat["saturation_pct"] <= 1).all()

        # Deciles must be in [1, 10]
        assert (sat["decile"] >= 1).all()
        assert (sat["decile"] <= 10).all()

    def test_saturation_with_many_categories(self) -> None:
        from rusket.analytics import customer_saturation

        df = _make_purchase_log(n_customers=80, n_categories=50, seed=55)
        sat = customer_saturation(df, user_col="customer", category_col="category")
        # Customers buying few of 50 categories should have low saturation
        assert sat["saturation_pct"].mean() < 0.5

    def test_find_substitutes_faker(self) -> None:
        """Build rules from Faker data and check find_substitutes doesn't crash."""
        import numpy as np

        from rusket import fpgrowth
        from rusket.analytics import find_substitutes

        fake = Faker()
        Faker.seed(123)
        rng = np.random.default_rng(123)

        products: list[str] = []
        seen: set[str] = set()
        while len(products) < 20:
            name = fake.word().capitalize()
            if name not in seen:
                seen.add(name)
                products.append(name)

        # Create two groups of products that never co-occur (potential substitutes)
        n = 200
        matrix = np.zeros((n, 20), dtype=bool)
        for i in range(n):
            if rng.random() < 0.5:
                matrix[i, :10] = rng.random(10) < 0.3
            else:
                matrix[i, 10:] = rng.random(10) < 0.3

        basket_df = pd.DataFrame(matrix, columns=products)
        freq = fpgrowth(basket_df, min_support=0.05, use_colnames=True)

        if len(freq) > 0:
            from rusket import association_rules

            rules = association_rules(freq, num_itemsets=n, metric="lift", min_threshold=0.01)
            if len(rules) > 0:
                subs = find_substitutes(rules, max_lift=0.8)
                assert isinstance(subs, pd.DataFrame)
