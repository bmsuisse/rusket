{
  "functions": {
    "mine": {
      "parameters": {
        "df": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
        "min_support": "float",
        "null_values": "bool",
        "use_colnames": "bool",
        "max_len": "int | None",
        "method": "str",
        "verbose": "int",
        "column_names": "list[str] | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Mine frequent itemsets using the optimal algorithm."
    },
    "fpgrowth": {
      "parameters": {
        "df": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
        "min_support": "float",
        "null_values": "bool",
        "use_colnames": "bool",
        "max_len": "int | None",
        "method": "str",
        "verbose": "int",
        "column_names": "list[str] | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Find frequent itemsets using the optimal algorithm (Eclat or FP-growth)."
    },
    "eclat": {
      "parameters": {
        "df": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
        "min_support": "float",
        "null_values": "bool",
        "use_colnames": "bool",
        "max_len": "int | None",
        "verbose": "int",
        "column_names": "list[str] | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Find frequent itemsets using the Eclat algorithm."
    },
    "association_rules": {
      "parameters": {
        "df": "pd.DataFrame | Any",
        "num_itemsets": "int | None",
        "df_orig": "pd.DataFrame | None",
        "null_values": "bool",
        "metric": "str",
        "min_threshold": "float",
        "support_only": "bool",
        "return_metrics": "list[str]"
      },
      "returns": "pd.DataFrame",
      "doc": ""
    },
    "prefixspan": {
      "parameters": {
        "sequences": "list[list[int]]",
        "min_support": "int | float",
        "max_len": "int | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Mine sequential patterns using the PrefixSpan algorithm."
    },
    "hupm": {
      "parameters": {
        "transactions": "list[list[int]]",
        "utilities": "list[list[float]]",
        "min_utility": "float",
        "max_len": "int | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Mine high-utility itemsets."
    },
    "sequences_from_event_log": {
      "parameters": {
        "df": "Any",
        "user_col": "str",
        "time_col": "str",
        "item_col": "str"
      },
      "returns": "tuple[list[list[int]], dict[int, Any]]",
      "doc": "Convert an event log DataFrame into the sequence format required by PrefixSpan."
    },
    "mine_hupm": {
      "parameters": {
        "data": "Any",
        "transaction_col": "str",
        "item_col": "str",
        "utility_col": "str",
        "min_utility": "float",
        "max_len": "int | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Mine high-utility itemsets from a long-format DataFrame."
    },
    "mine_duckdb": {
      "parameters": {
        "con": "Any",
        "query": "str",
        "n_items": "int",
        "txn_col": "str",
        "item_col": "str",
        "min_support": "float",
        "max_len": "int | None",
        "chunk_size": "int"
      },
      "returns": "pd.DataFrame",
      "doc": "Stream directly from a DuckDB query via Arrow RecordBatches."
    },
    "mine_spark": {
      "parameters": {
        "spark_df": "Any",
        "n_items": "int",
        "txn_col": "str",
        "item_col": "str",
        "min_support": "float",
        "max_len": "int | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Stream natively from a PySpark DataFrame on Databricks via Arrow."
    },
    "from_transactions": {
      "parameters": {
        "data": "DataFrame | Sequence[Sequence[str | int]] | Any",
        "transaction_col": "str | None",
        "item_col": "str | None",
        "min_item_count": "int",
        "verbose": "int"
      },
      "returns": "Any",
      "doc": "Convert long-format transactional data to a one-hot boolean matrix."
    },
    "from_transactions_csr": {
      "parameters": {
        "data": "DataFrame | str | Any",
        "transaction_col": "str | None",
        "item_col": "str | None",
        "chunk_size": "int"
      },
      "returns": "tuple[Any, list[str]]",
      "doc": "Convert long-format transactional data to a CSR matrix + column names."
    },
    "from_pandas": {
      "parameters": {
        "df": "pd.DataFrame",
        "transaction_col": "str | None",
        "item_col": "str | None",
        "min_item_count": "int",
        "verbose": "int"
      },
      "returns": "pd.DataFrame",
      "doc": "Shorthand for ``from_transactions(df, transaction_col, item_col)``."
    },
    "from_polars": {
      "parameters": {
        "df": "pl.DataFrame",
        "transaction_col": "str | None",
        "item_col": "str | None",
        "min_item_count": "int",
        "verbose": "int"
      },
      "returns": "pl.DataFrame",
      "doc": "Shorthand for ``from_transactions(df, transaction_col, item_col)``."
    },
    "from_spark": {
      "parameters": {
        "df": "SparkDataFrame",
        "transaction_col": "str | None",
        "item_col": "str | None",
        "min_item_count": "int",
        "verbose": "int"
      },
      "returns": "SparkDataFrame",
      "doc": "Shorthand for ``from_transactions(df, transaction_col, item_col)``."
    },
    "score_potential": {
      "parameters": {
        "user_history": "list[list[int]]",
        "model": "Any",
        "target_categories": "list[int] | None"
      },
      "returns": "np.ndarray",
      "doc": "Cross-selling potential scores \u2014 shape ``(n_users, n_items)`` or ``(n_users, len(target_categories))``."
    },
    "similar_items": {
      "parameters": {
        "model": "SupportsItemFactors",
        "item_id": "int",
        "n": "int"
      },
      "returns": "tuple[np.ndarray, np.ndarray]",
      "doc": "Find the most similar items to a given item ID based on latent factors."
    },
    "find_substitutes": {
      "parameters": {
        "rules_df": "pd.DataFrame",
        "max_lift": "float"
      },
      "returns": "pd.DataFrame",
      "doc": "Substitute/cannibalizing products via negative association rules."
    },
    "customer_saturation": {
      "parameters": {
        "df": "pd.DataFrame",
        "user_col": "str",
        "category_col": "str | None",
        "item_col": "str | None"
      },
      "returns": "pd.DataFrame",
      "doc": "Customer saturation by unique items/categories bought, split into deciles."
    },
    "export_item_factors": {
      "parameters": {
        "model": "SupportsItemFactors",
        "include_labels": "bool",
        "normalize": "bool",
        "format": "str"
      },
      "returns": "Any",
      "doc": "Exports latent item factors as a DataFrame for Vector DBs."
    },
    "from_arrow": {
      "parameters": {
        "table": "pa.Table",
        "transaction_col": "str | None",
        "item_col": "str | None",
        "min_item_count": "int",
        "verbose": "int"
      },
      "returns": "pa.Table",
      "doc": "Convert a PyArrow Table in long format to a one-hot boolean PyArrow Table."
    },
    "evaluate": {
      "parameters": {
        "model": "Any",
        "test_interactions": "Any",
        "k": "int",
        "metrics": "list[MetricName] | None"
      },
      "returns": "dict[str, float]",
      "doc": "Evaluate a trained recommendation model on a test set."
    },
    "train_test_split": {
      "parameters": {
        "df": "Any",
        "user_col": "str",
        "item_col": "str",
        "test_size": "float",
        "random_state": "int | None"
      },
      "returns": "Any",
      "doc": "Split interactions into random train and test sets."
    },
    "leave_one_out_split": {
      "parameters": {
        "df": "Any",
        "user_col": "str",
        "item_col": "str",
        "timestamp_col": "str | None"
      },
      "returns": "Any",
      "doc": "Leave exactly one interaction per user for the test set."
    },
    "pca": {
      "parameters": {
        "x": "npt.NDArray[Any]",
        "n_components": "int",
        "svd_solver": "str"
      },
      "returns": "ProjectedSpace",
      "doc": "Project data into `n_components` dimensions using PCA."
    },
    "pca2": {
      "parameters": {
        "x": "npt.NDArray[Any]",
        "svd_solver": "str"
      },
      "returns": "ProjectedSpace",
      "doc": "Project data into exactly 2 dimensions using PCA."
    },
    "pca3": {
      "parameters": {
        "x": "npt.NDArray[Any]",
        "svd_solver": "str"
      },
      "returns": "ProjectedSpace",
      "doc": "Project data into exactly 3 dimensions using PCA."
    }
  },
  "classes": {
    "FPGrowth": {
      "methods": {
        "__init__": {
          "parameters": {
            "data": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
            "item_names": "list[str] | None",
            "min_support": "float",
            "null_values": "bool",
            "use_colnames": "bool",
            "max_len": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize the FPGrowth miner."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Execute the FP-growth algorithm on the stored data."
        }
      },
      "doc": "FP-Growth frequent itemset miner."
    },
    "Eclat": {
      "methods": {
        "__init__": {
          "parameters": {
            "data": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
            "item_names": "list[str] | None",
            "min_support": "float",
            "null_values": "bool",
            "use_colnames": "bool",
            "max_len": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize the Eclat miner."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Execute the Eclat algorithm on the stored data."
        }
      },
      "doc": "Eclat frequent itemset miner."
    },
    "AutoMiner": {
      "methods": {
        "__init__": {
          "parameters": {
            "data": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
            "item_names": "list[str] | None",
            "min_support": "float",
            "null_values": "bool",
            "use_colnames": "bool",
            "max_len": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize the automatic miner."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Execute the optimal algorithm on the stored data."
        }
      },
      "doc": "Automatic frequent itemset miner."
    },
    "PrefixSpan": {
      "methods": {
        "__init__": {
          "parameters": {
            "data": "list[list[int]]",
            "min_support": "int | float",
            "max_len": "int | None",
            "item_mapping": "dict[int, Any] | None"
          },
          "returns": "Any",
          "doc": "Initialize PrefixSpan with an already-formatted sequence list."
        },
        "from_transactions": {
          "parameters": {
            "data": "Any",
            "transaction_col": "str | None",
            "item_col": "str | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "PrefixSpan",
          "doc": "Initialize the PrefixSpan model from an event log DataFrame."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Mine sequential patterns using PrefixSpan."
        },
        "mine_grouped": {
          "parameters": {
            "df": "Any",
            "group_col": "str",
            "user_col": "str",
            "time_col": "str",
            "item_col": "str",
            "min_support": "int",
            "max_len": "int | None"
          },
          "returns": "Any",
          "doc": "Distribute Sequential Pattern Mining (PrefixSpan) across PySpark partitions."
        }
      },
      "doc": "Sequential Pattern Mining (PrefixSpan) model."
    },
    "HUPM": {
      "methods": {
        "__init__": {
          "parameters": {
            "transactions": "list[list[int]]",
            "utilities": "list[list[float]]",
            "min_utility": "float",
            "max_len": "int | None"
          },
          "returns": "Any",
          "doc": "Initialize HUPM with pre-formatted transactions and utilities."
        },
        "from_transactions": {
          "parameters": {
            "data": "Any",
            "transaction_col": "str | None",
            "item_col": "str | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "HUPM",
          "doc": "Initialize the HUPM model from a long-format DataFrame."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Mine high-utility itemsets."
        },
        "mine_grouped": {
          "parameters": {
            "df": "Any",
            "group_col": "str",
            "transaction_col": "str",
            "item_col": "str",
            "utility_col": "str",
            "min_utility": "float",
            "max_len": "int | None"
          },
          "returns": "Any",
          "doc": "Distribute High-Utility Pattern Mining (HUPM) across PySpark partitions."
        }
      },
      "doc": "High-Utility Pattern Mining (HUPM) model."
    },
    "FPMiner": {
      "methods": {
        "__init__": {
          "parameters": {
            "n_items": "int",
            "max_ram_mb": "int | None",
            "hint_n_transactions": "int | None"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "add_arrow_batch": {
          "parameters": {
            "batch": "Any",
            "txn_col": "str",
            "item_col": "str"
          },
          "returns": "FPMiner",
          "doc": "Feed a PyArrow RecordBatch directly into the miner."
        },
        "add_chunk": {
          "parameters": {
            "txn_ids": "np.ndarray",
            "item_ids": "np.ndarray"
          },
          "returns": "FPMiner",
          "doc": "Feed a chunk of (transaction_id, item_id) pairs."
        },
        "fit": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "FPMiner",
          "doc": "Sklearn-compatible alias for ``mine()``. Runs the mining algorithm."
        },
        "mine": {
          "parameters": {
            "min_support": "float",
            "max_len": "int | None",
            "use_colnames": "bool",
            "column_names": "list[str] | None",
            "method": "Literal['fpgrowth', 'eclat', 'auto']",
            "verbose": "int"
          },
          "returns": "pd.DataFrame",
          "doc": "Mine frequent itemsets from all accumulated transactions."
        },
        "predict": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Return the last mined result, or run ``fit()`` first."
        },
        "reset": {
          "parameters": {},
          "returns": "None",
          "doc": "Free all accumulated data."
        }
      },
      "doc": "Streaming FP-Growth / Eclat accumulator for billion-row datasets."
    },
    "ALS": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "regularization": "float",
            "alpha": "float",
            "iterations": "int",
            "seed": "int",
            "verbose": "int",
            "cg_iters": "int",
            "use_cholesky": "bool",
            "anderson_m": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "batch_recommend": {
          "parameters": {
            "n": "int",
            "exclude_seen": "bool",
            "format": "str"
          },
          "returns": "Any",
          "doc": "Top-N items for all users efficiently computed in parallel."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "ALS",
          "doc": "Fit the model to the user-item interaction matrix."
        },
        "recalculate_user": {
          "parameters": {
            "user_items": "Any"
          },
          "returns": "np.ndarray",
          "doc": "Calculate the latent factors for a new or existing user given their interacted items."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N items for a user. Set exclude_seen=False to include already-seen items."
        },
        "recommend_users": {
          "parameters": {
            "item_id": "int",
            "n": "int"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N users for an item."
        }
      },
      "doc": "Implicit ALS collaborative filtering model."
    },
    "BPR": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "learning_rate": "float",
            "regularization": "float",
            "iterations": "int",
            "seed": "int",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "BPR",
          "doc": "Fit the BPR model to the user-item interaction matrix."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N items for a user."
        }
      },
      "doc": "Bayesian Personalized Ranking (BPR) model for implicit feedback."
    },
    "FM": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "learning_rate": "float",
            "regularization": "float",
            "iterations": "int",
            "seed": "int",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "X": "Any",
            "y": "Any"
          },
          "returns": "FM",
          "doc": "Fit the FM model to Context-aware Data."
        },
        "from_transactions": {
          "parameters": {
            "args": "Any",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize the model from a long-format DataFrame or sequences."
        },
        "predict": {
          "parameters": {
            "X": "Any"
          },
          "returns": "Any",
          "doc": "Alias for :meth:`predict_proba`."
        },
        "predict_proba": {
          "parameters": {
            "X": "Any"
          },
          "returns": "Any",
          "doc": "Predict the probability (CTR) of interactions."
        }
      },
      "doc": "Factorization Machines (FM) context-aware model for predictive tasks (e.g. CTR)."
    },
    "Recommender": {
      "methods": {
        "__init__": {
          "parameters": {
            "model": "Any | None",
            "rules_df": "pd.DataFrame | None",
            "item_embeddings": "np.ndarray | None"
          },
          "returns": "Any",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "predict_next_chunk": {
          "parameters": {
            "user_history_df": "pd.DataFrame",
            "user_col": "str",
            "k": "int"
          },
          "returns": "pd.DataFrame",
          "doc": "Batch-rank the next best products for every user in *user_history_df*."
        },
        "recommend_for_cart": {
          "parameters": {
            "cart_items": "list[int]",
            "n": "int"
          },
          "returns": "list[int]",
          "doc": "Suggest items to add to an active cart using association rules."
        },
        "recommend_for_user": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "alpha": "float",
            "target_item_for_semantic": "int | None"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Top-N recommendations for a user via Hybrid ALS + Semantic."
        }
      },
      "doc": "Hybrid recommender combining ALS collaborative filtering, semantic similarities, and association rules."
    },
    "NextBestAction": {
      "methods": {
        "__init__": {
          "parameters": {
            "model": "Any | None",
            "rules_df": "pd.DataFrame | None",
            "item_embeddings": "np.ndarray | None"
          },
          "returns": "Any",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "predict_next_chunk": {
          "parameters": {
            "user_history_df": "pd.DataFrame",
            "user_col": "str",
            "k": "int"
          },
          "returns": "pd.DataFrame",
          "doc": "Batch-rank the next best products for every user in *user_history_df*."
        },
        "recommend_for_cart": {
          "parameters": {
            "cart_items": "list[int]",
            "n": "int"
          },
          "returns": "list[int]",
          "doc": "Suggest items to add to an active cart using association rules."
        },
        "recommend_for_user": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "alpha": "float",
            "target_item_for_semantic": "int | None"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Top-N recommendations for a user via Hybrid ALS + Semantic."
        }
      },
      "doc": "Hybrid recommender combining ALS collaborative filtering, semantic similarities, and association rules."
    },
    "FIN": {
      "methods": {
        "__init__": {
          "parameters": {
            "data": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
            "item_names": "list[str] | None",
            "min_support": "float",
            "null_values": "bool",
            "use_colnames": "bool",
            "max_len": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize the FIN miner."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Execute the FIN algorithm on the stored data."
        }
      },
      "doc": "FIN (Fast Itemset per Nodeset) frequent itemset miner."
    },
    "LCM": {
      "methods": {
        "__init__": {
          "parameters": {
            "data": "pd.DataFrame | pl.DataFrame | np.ndarray | Any",
            "item_names": "list[str] | None",
            "min_support": "float",
            "null_values": "bool",
            "use_colnames": "bool",
            "max_len": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize the LCM miner."
        },
        "mine": {
          "parameters": {
            "kwargs": "Any"
          },
          "returns": "pd.DataFrame",
          "doc": "Execute the LCM algorithm on the stored data to find closed itemsets."
        }
      },
      "doc": "LCM (Linear Closed Itemset Miner) frequent itemset miner."
    },
    "EASE": {
      "methods": {
        "__init__": {
          "parameters": {
            "regularization": "float",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "EASE",
          "doc": "Fit the model to the user-item interaction matrix."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N items for a user. Set exclude_seen=False to include already-seen items."
        }
      },
      "doc": "Embarrassingly Shallow Autoencoders for Sparse Data (EASE)."
    },
    "ItemKNN": {
      "methods": {
        "__init__": {
          "parameters": {
            "method": "Literal['bm25', 'tfidf', 'cosine', 'count']",
            "k": "int",
            "bm25_k1": "float",
            "bm25_b": "float",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "Any",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "ItemKNN",
          "doc": "Fit the ItemKNN model."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N items for a user."
        }
      },
      "doc": "Ultra-fast Sparse Item-Item K-Nearest Neighbors Recommender."
    },
    "FPMC": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "learning_rate": "float",
            "regularization": "float",
            "iterations": "int",
            "seed": "int",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "sequences": "list[list[int]] | None",
            "n_items": "int | None"
          },
          "returns": "FPMC",
          "doc": "Fit the FPMC model to a list of sequential interactions."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N sequential items for a user."
        }
      },
      "doc": "Factorizing Personalized Markov Chains (FPMC) model for sequential recommendation."
    },
    "SVD": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "learning_rate": "float",
            "regularization": "float",
            "iterations": "int",
            "seed": "int",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "batch_recommend": {
          "parameters": {
            "n": "int",
            "exclude_seen": "bool",
            "format": "str"
          },
          "returns": "Any",
          "doc": "Top-N items for all users efficiently computed in parallel."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "SVD",
          "doc": "Fit the model to the user-item interaction matrix."
        },
        "predict": {
          "parameters": {
            "user_id": "int",
            "item_id": "int"
          },
          "returns": "float",
          "doc": "Predict the rating for a user-item pair."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N items for a user."
        },
        "recommend_users": {
          "parameters": {
            "item_id": "int",
            "n": "int"
          },
          "returns": "tuple[Any, Any]",
          "doc": "Top-N users for an item."
        }
      },
      "doc": "Funk SVD collaborative filtering model."
    },
    "LightGCN": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "k_layers": "int",
            "learning_rate": "float",
            "lambda_": "float",
            "iterations": "int",
            "seed": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "LightGCN",
          "doc": "Fit the model to a user-item interaction matrix."
        },
        "from_transactions": {
          "parameters": {
            "data": "pd.DataFrame | pl.DataFrame | Any",
            "transaction_col": "str | None",
            "item_col": "str | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "LightGCN",
          "doc": "Initialize the LightGCN model from a long-format DataFrame."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Top-N items for a user."
        }
      },
      "doc": "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation."
    },
    "SASRec": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "n_layers": "int",
            "max_seq": "int",
            "learning_rate": "float",
            "lambda_": "float",
            "iterations": "int",
            "seed": "int | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "sequences": "list[list[int]] | None"
          },
          "returns": "SASRec",
          "doc": "Train SASRec on integer-encoded sequences (0-indexed item IDs)."
        },
        "from_transactions": {
          "parameters": {
            "data": "Any",
            "transaction_col": "str | None",
            "item_col": "str | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "SASRec",
          "doc": "Prepare SASRec from a transactions DataFrame."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int | list[int]",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Top-N items for a user or an ad-hoc sequence."
        }
      },
      "doc": "SASRec \u2013 Self-Attentive Sequential Recommendation."
    },
    "PopularityRecommender": {
      "methods": {
        "__init__": {
          "parameters": {
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "PopularityRecommender",
          "doc": "Fit the model by counting interactions per item."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Return the *n* most popular items for a user."
        }
      },
      "doc": "Recommend items by global popularity (interaction count)."
    },
    "ContentBased": {
      "methods": {
        "__init__": {
          "parameters": {
            "max_features": "int",
            "ngram_range": "tuple[int, int]",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {},
          "returns": "ContentBased",
          "doc": "Compute TF-IDF vectors and the pairwise cosine similarity matrix."
        },
        "from_dataframe": {
          "parameters": {
            "df": "Any",
            "item_col": "str",
            "text_col": "str",
            "kwargs": "Any"
          },
          "returns": "ContentBased",
          "doc": "Build a content-based recommender from item metadata."
        },
        "from_transactions": {
          "parameters": {
            "data": "Any",
            "transaction_col": "str | None",
            "item_col": "str | None",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "ContentBased",
          "doc": "Not applicable for content-based filtering."
        },
        "recommend_similar": {
          "parameters": {
            "item": "Any",
            "n": "int"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Find the *n* most similar items to a given item."
        }
      },
      "doc": "Content-based recommender using TF-IDF vectorization and cosine similarity."
    },
    "HybridRecommender": {
      "methods": {
        "__init__": {
          "parameters": {
            "models_and_weights": "list[tuple[Any, float]]"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {},
          "returns": "HybridRecommender",
          "doc": "No-op \u2014 constituent models must be pre-fitted."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Blend recommendations from all constituent models."
        }
      },
      "doc": "Weighted ensemble of multiple recommendation models."
    },
    "NMF": {
      "methods": {
        "__init__": {
          "parameters": {
            "factors": "int",
            "iterations": "int",
            "regularization": "float",
            "seed": "int",
            "verbose": "int",
            "kwargs": "Any"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "interactions": "Any"
          },
          "returns": "NMF",
          "doc": "Fit via multiplicative update rules."
        },
        "recommend_items": {
          "parameters": {
            "user_id": "int",
            "n": "int",
            "exclude_seen": "bool"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Top-N items for a user via W @ H^T."
        }
      },
      "doc": "Non-negative Matrix Factorization for collaborative filtering."
    },
    "PCA": {
      "methods": {
        "__init__": {
          "parameters": {
            "n_components": "int",
            "svd_solver": "str"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "fit": {
          "parameters": {
            "X": "npt.NDArray[Any]"
          },
          "returns": "PCA",
          "doc": "Fit PCA on the data matrix ``X``."
        },
        "fit_transform": {
          "parameters": {
            "X": "npt.NDArray[Any]"
          },
          "returns": "npt.NDArray[np.float32]",
          "doc": "Fit the model with ``X`` and apply dimensionality reduction."
        },
        "transform": {
          "parameters": {
            "X": "npt.NDArray[Any]"
          },
          "returns": "npt.NDArray[np.float32]",
          "doc": "Apply dimensionality reduction to ``X``."
        }
      },
      "doc": "Principal Component Analysis (PCA)."
    },
    "Pipeline": {
      "methods": {
        "__init__": {
          "parameters": {
            "retrieve": "Any | list[Any] | None",
            "rerank": "Any | None",
            "filter": "Callable[[list[Any], list[float]], tuple[list[Any], list[float]]] | None",
            "merge_strategy": "Literal['max', 'mean', 'sum']"
          },
          "returns": "None",
          "doc": "Initialize self.  See help(type(self)) for accurate signature."
        },
        "recommend": {
          "parameters": {
            "user_id": "int | Any",
            "n": "int",
            "exclude_seen": "bool",
            "retrieve_k": "int | None"
          },
          "returns": "tuple[np.ndarray, np.ndarray]",
          "doc": "Run the full pipeline for a single user."
        },
        "recommend_batch": {
          "parameters": {
            "user_ids": "list[int | Any] | np.ndarray | None",
            "n": "int",
            "exclude_seen": "bool",
            "retrieve_k": "int | None",
            "format": "str"
          },
          "returns": "Any",
          "doc": "Batch recommendations for multiple users."
        }
      },
      "doc": "Multi-stage recommendation pipeline."
    }
  },
  "spark": {
    "mine_grouped": {
      "parameters": {
        "df": "Any",
        "group_col": "str",
        "min_support": "float",
        "max_len": "int | None",
        "method": "str",
        "use_colnames": "bool"
      },
      "returns": "Any",
      "doc": "Distribute Market Basket Analysis across PySpark partitions."
    },
    "rules_grouped": {
      "parameters": {
        "df": "Any",
        "group_col": "str",
        "num_itemsets": "dict[Any, int] | int",
        "metric": "str",
        "min_threshold": "float"
      },
      "returns": "Any",
      "doc": "Distribute Association Rule Mining across PySpark partitions."
    },
    "prefixspan_grouped": {
      "parameters": {
        "df": "Any",
        "group_col": "str",
        "user_col": "str",
        "time_col": "str",
        "item_col": "str",
        "min_support": "int",
        "max_len": "int | None"
      },
      "returns": "Any",
      "doc": "Distribute Sequential Pattern Mining (PrefixSpan) across PySpark partitions."
    },
    "hupm_grouped": {
      "parameters": {
        "df": "Any",
        "group_col": "str",
        "transaction_col": "str",
        "item_col": "str",
        "utility_col": "str",
        "min_utility": "float",
        "max_len": "int | None"
      },
      "returns": "Any",
      "doc": "Distribute High-Utility Pattern Mining (HUPM) across PySpark partitions."
    },
    "recommend_batches": {
      "parameters": {
        "df": "Any",
        "model": "Any",
        "user_col": "str",
        "k": "int"
      },
      "returns": "Any",
      "doc": "Distribute Batch Recommendations across PySpark partitions."
    },
    "to_spark": {
      "parameters": {
        "spark_session": "Any",
        "df": "Any"
      },
      "returns": "Any",
      "doc": "Convert a Pandas or Polars DataFrame into a PySpark DataFrame."
    }
  }
}