---
title: "Quick Start"
description: "Install rusket and run your first Market Basket Analysis in minutes."
---

## Installation

<Tabs>
  <Tab title="pip">
    ```bash
    pip install rusket
    ```
  </Tab>
  <Tab title="uv">
    ```bash
    uv add rusket
    ```
  </Tab>
  <Tab title="conda">
    ```bash
    pip install rusket  # rusket is not on conda-forge yet
    ```
  </Tab>
</Tabs>

To also enable **Polars** support:

<Tabs>
  <Tab title="pip">
    ```bash
    pip install "rusket[polars]"
    ```
  </Tab>
  <Tab title="uv">
    ```bash
    uv add "rusket[polars]"
    ```
  </Tab>
</Tabs>

<Tip>
**Coming from mlxtend?** rusket is a **drop-in replacement**. In most cases you only need to change your import:
```python
# Before
from mlxtend.frequent_patterns import fpgrowth, association_rules
# After
from rusket import mine, association_rules
```
See the full [Migration Guide](/migration) for details.
</Tip>

---

## Business Scenario — Supermarket Cross-Selling

Suppose a supermarket chain wants to identify which products to promote together.
The raw data arrives as a checkout log where each row is one receipt.

## Step 1 — Prepare your data

`mine` expects a **one-hot encoded** DataFrame where rows are transactions and columns are products.

Most real-world data comes as long-format order lines (one row per product per order). `from_transactions` converts that in one call:

```python
import pandas as pd
from rusket import from_transactions

# Raw checkout log from a POS system
orders = pd.DataFrame({
    "receipt_id": [1001, 1001, 1001, 1002, 1002, 1003, 1003, 1004],
    "product":    ["milk", "bread", "butter",
                   "milk", "eggs",
                   "bread", "butter",
                   "milk", "bread", "eggs", "coffee"],
})

# One-hot encode: rows = receipts, columns = products
basket = from_transactions(orders, transaction_col="receipt_id", item_col="product")
print(basket)
#        milk  bread  butter  eggs  coffee
# 1001   True   True    True False   False
# 1002   True  False   False  True   False
# 1003  False   True    True False   False
# 1004   True   True   False  True    True
```

---

## Step 2 — Mine frequent product combinations

```python
from rusket import mine

# method="auto" automatically selects FP-Growth or Eclat based on catalogue density
freq = mine(basket, min_support=0.4, use_colnames=True)
print(freq.sort_values("support", ascending=False))
#    support          itemsets
# 0     0.75          (milk,)
# 1     0.75         (bread,)
# 2     0.50         (butter,)
# 3     0.50    (milk, bread,)
# 4     0.50  (bread, butter,)
```

---

## Step 2b — Or use Eclat for sparse, large catalogues

ECLAT is faster for retailers with thousands of SKUs and typical basket sizes of 3–5 items.

```python
from rusket import eclat

freq = eclat(basket, min_support=0.4, use_colnames=True)
print(freq)  # identical output to fpgrowth
```

<Tip>
`mine(method="auto")` handles this automatically: it picks `eclat` for sparse data (density < 0.15, typical for large SKU catalogs) and `fpgrowth` for dense data.
</Tip>

---

## Step 3 — Generate "Frequently Bought Together" rules

```python
from rusket import association_rules

rules = association_rules(
    freq,
    num_itemsets=len(basket),
    metric="confidence",
    min_threshold=0.6,
)
print(rules[["antecedents", "consequents", "support", "confidence", "lift"]])
# antecedents consequents  support  confidence  lift
# (bread,)    (butter,)      0.50        0.67   1.33
# (butter,)   (bread,)       0.50        1.00   1.33
```

**Interpreting the output:**

- **Confidence 0.67** → 67% of customers who buy bread also buy butter.
- **Lift 1.33** → customers who buy bread are 1.33× more likely to buy butter compared to random.

Use these rules to power your "Customers also buy" widgets, shelf placement decisions, or promotional bundles.

<Note>
Pass the **total transaction count** (`len(basket)`) as `num_itemsets` so that support-based metrics are computed correctly.
</Note>

---

## OOP API — Fluent Pipeline

If you prefer a single chained API from raw data down to recommendations:

```python
from rusket import AutoMiner

model = AutoMiner.from_transactions(orders, transaction_col="receipt_id", item_col="product", min_support=0.4)
freq  = model.mine(use_colnames=True)
rules = model.association_rules(metric="lift", min_threshold=1.0)

# "What else should go in the basket?" — cart recommendations
basket_contents = ["milk", "bread"]
suggestions = model.recommend_items(basket_contents, n=3)
print(suggestions)  # e.g. ["butter", "eggs", "coffee"]
```

---

## Billion-Scale Streaming

For retailers with hundreds of millions of transactions that don't fit in memory, use `FPMiner` to stream data chunk-by-chunk:

```python
from rusket import FPMiner

miner = FPMiner(n_items=500_000)  # total distinct SKUs

# Read your fact table in chunks — e.g. from S3 Parquet or an API cursor
for chunk in pd.read_parquet("sales_fact.parquet", chunksize=10_000_000):
    txn  = chunk["receipt_id"].to_numpy(dtype="int64")
    item = chunk["product_idx"].to_numpy(dtype="int32")  # 0-based SKU index
    miner.add_chunk(txn, item)

# Mine — all data in Rust, output is a normal pandas DataFrame
freq  = miner.mine(min_support=0.001, max_len=3)
rules = association_rules(freq, num_itemsets=miner.n_transactions)
```

<Tip>
Peak Python memory = one chunk (typically 1–2 GB). Rust holds the per-transaction item lists (~5 GB for 200M transactions). The final mining step passes CSR arrays directly — zero copies.
</Tip>

### Direct CSR path

If you already have integer arrays from a data warehouse query, skip `from_transactions` entirely:

```python
from scipy import sparse as sp
from rusket import mine

csr = sp.csr_matrix(
    (np.ones(len(receipt_ids), dtype=np.int8), (receipt_ids, sku_indices)),
    shape=(n_receipts, n_skus),
)
freq = mine(csr, min_support=0.001, column_names=sku_names)
```

---

## What's Next?

<CardGroup cols={2}>
  <Card title="Migration from mlxtend" icon="arrow-right-arrow-left" href="/migration">
    Side-by-side API comparison
  </Card>
  <Card title="API Reference" icon="book" href="/api-reference">
    All parameters and metrics explained
  </Card>
  <Card title="Polars Support" icon="zap" href="/polars">
    Zero-copy Arrow path
  </Card>
  <Card title="Recommender Workflows" icon="sparkles" href="/recommender">
    Personalised recommendations for users
  </Card>
</CardGroup>
