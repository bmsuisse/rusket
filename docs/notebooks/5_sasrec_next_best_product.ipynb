{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SASRec: Session-Based Next-Best-Product\n",
    "\n",
    "**Business problem:** Your store has many **anonymous / new visitors** â€” they have no purchase history at all. Classical collaborative filtering (ALS, BPR, LightGCN) cannot help them because they have no embeddings. But you *do* know what they clicked on in the current session.\n",
    "\n",
    "**Why SASRec?** Unlike Markov-chain models (FPMC), the **self-attention mechanism** captures *long-range dependencies* within a session â€” so a user who browsed Espresso Maker â†’ Grinder â†’ Scales is likely interested in whole-bean Coffee, not in unrelated items that appear in simple co-occurrence tables.\n",
    "\n",
    "Use cases covered:\n",
    "1. **Real-time next-product widget** â€” \"Based on what you've viewedâ€¦\"\n",
    "2. **Personalised push notification** â€” what to show a user who hasn't returned in 7 days\n",
    "3. **Session-quality score** â€” how focused / intentional is this browse session?\n",
    "4. **Cart abandonment recovery** â€” predict what the user intended to buy but didn't\n",
    "\n",
    "> **Dataset:** MovieLens 100k (publicly available). We treat each user's chronological viewing history as a browse session, and model \"what they watch next\" â€” the exact same pattern as \"what they buy next\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request, zipfile, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rusket\n",
    "from rusket import SASRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Sequential (Session-Based) Data\n",
    "\n",
    "SASRec learns from **ordered sequences**. The key difference from collaborative filtering is that the **order of interactions matters** â€” we sort by timestamp and treat each user's history as a single sequential session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Download MovieLens 100k â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if not os.path.exists(\"ml-100k\"):\n",
    "    url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    urllib.request.urlretrieve(url, \"ml-100k.zip\")\n",
    "    with zipfile.ZipFile(\"ml-100k.zip\") as z:\n",
    "        z.extractall(\".\")\n",
    "\n",
    "cols = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "df = pd.read_csv(\"ml-100k/u.data\", sep=\"\\t\", names=cols)\n",
    "\n",
    "# Load item (movie) names\n",
    "movies = pd.read_csv(\n",
    "    \"ml-100k/u.item\", sep=\"|\", encoding=\"latin-1\",\n",
    "    header=None, usecols=[0, 1], names=[\"item_id\", \"title\"]\n",
    ").set_index(\"item_id\")[\"title\"]\n",
    "\n",
    "print(f\"Loaded {len(df):,} ratings | {df['user_id'].nunique():,} users | {df['item_id'].nunique():,} movies\")\n",
    "\n",
    "# â”€â”€ Build chronological sequences per user â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_sorted = df.sort_values([\"user_id\", \"timestamp\"])\n",
    "sequences_df = df_sorted.groupby(\"user_id\")[\"item_id\"].apply(list)\n",
    "\n",
    "# Stats\n",
    "lengths = sequences_df.map(len)\n",
    "print(f\"\\nSession length: min={lengths.min()} | median={lengths.median():.0f} | max={lengths.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train / Validation Split\n",
    "\n",
    "We use the standard **leave-one-out** evaluation: the last item in each user's history is held out as the ground truth. The model must predict it from the preceding context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs, val_truth = [], []\n",
    "for seq in sequences_df:\n",
    "    if len(seq) >= 2:\n",
    "        train_seqs.append(seq[:-1])   # context\n",
    "        val_truth.append(seq[-1])     # held-out ground truth\n",
    "\n",
    "print(f\"Training sequences : {len(train_seqs):,}\")\n",
    "print(f\"Validation targets : {len(val_truth):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train SASRec\n",
    "\n",
    "We use `from_transactions` which handles item encoding internally. For clean evaluation we use explicit sequences from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "\n",
    "model = SASRec.from_transactions(\n",
    "    df,\n",
    "    user_col=\"user_id\",\n",
    "    item_col=\"item_id\",\n",
    "    timestamp_col=\"timestamp\",\n",
    "    factors=64,\n",
    "    n_layers=2,\n",
    "    max_seq=50,         # use last 50 interactions as context\n",
    "    learning_rate=5e-4,\n",
    "    iterations=15,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "print(f\"âš¡ SASRec trained in {time.perf_counter() - t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-Time \"Based on What You've Viewed\" Widget\n",
    "\n",
    "This is the core **anonymous-visitor use case**. We receive the current browse session as a list of item IDs clicked in this visit (no login required) and instantly return ranked recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_best_widget(session_item_ids: list[int], n: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a browse session (original item IDs), return top-n recommendations.\n",
    "    Works for completely new / anonymous users.\n",
    "    \"\"\"\n",
    "    # Encode to internal IDs\n",
    "    encoded = [model._item_map[i] for i in session_item_ids if i in model._item_map]\n",
    "    if not encoded:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ids, scores = model.recommend_items(\n",
    "        user_sequence=encoded,\n",
    "        n=n,\n",
    "        exclude=encoded,   # don't re-recommend already-seen items\n",
    "    )\n",
    "    return pd.DataFrame({\n",
    "        \"item_id\"   : [model._rev_item_map.get(i, i) for i in ids],\n",
    "        \"title\"     : [movies.get(model._rev_item_map.get(i, i), \"?\") for i in ids],\n",
    "        \"score\"     : np.round(scores, 3),\n",
    "    })\n",
    "\n",
    "# Simulate a visitor who watched 3 sci-fi films\n",
    "sci_fi_session = [50, 100, 258]   # Star Wars, Fargo, Contact (MovieLens IDs)\n",
    "print(\"ðŸŽ¬ Current session:\")\n",
    "for i in sci_fi_session:\n",
    "    print(f\"   {movies.get(i, i)}\")\n",
    "print(\"\\nðŸ’¡ Next recommendations:\")\n",
    "print(next_best_widget(sci_fi_session).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Re-Engagement Push Notification\n",
    "\n",
    "A user hasn't returned in 7 days. We know their last viewed items. Instead of sending a generic 'We miss you', we can surface the **single most relevant** item to feature in the subject line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_engagement_item(user_id: int) -> str:\n",
    "    \"\"\"Return the single top recommendation for a lapsed user.\"\"\"\n",
    "    seq = sequences_df.get(user_id, [])\n",
    "    if not seq:\n",
    "        return \"No history found.\"\n",
    "\n",
    "    # Use last 10 interactions as context\n",
    "    context = seq[-10:]\n",
    "    encoded = [model._item_map[i] for i in context if i in model._item_map]\n",
    "    if not encoded:\n",
    "        return \"Items not in model.\"\n",
    "\n",
    "    ids, _ = model.recommend_items(user_sequence=encoded, n=1, exclude=encoded)\n",
    "    if not len(ids):\n",
    "        return \"No recommendations.\"\n",
    "    rec_id = model._rev_item_map.get(ids[0], ids[0])\n",
    "    return movies.get(rec_id, str(rec_id))\n",
    "\n",
    "# Simulate notification copy for 5 lapsed users\n",
    "lapsed_users = sequences_df.index[:5].tolist()\n",
    "print(\"ðŸ“§ Re-engagement notifications:\")\n",
    "for uid in lapsed_users:\n",
    "    rec = re_engagement_item(uid)\n",
    "    print(f\"   User {uid}: \\\"We thought you'd love: {rec}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cart Abandonment Recovery\n",
    "\n",
    "A user added items to cart but didn't complete checkout. Using the cart contents as the session context, we predict what else they might want â€” giving the sales team a high-confidence upsell script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_abandonment_upsell(cart_item_ids: list[int], n: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given items in an abandoned cart, predict likely next purchase intention.\n",
    "    The sales team / email copy can nudge the user toward completing the order.\n",
    "    \"\"\"\n",
    "    encoded = [model._item_map[i] for i in cart_item_ids if i in model._item_map]\n",
    "    if not encoded:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ids, scores = model.recommend_items(user_sequence=encoded, n=n, exclude=encoded)\n",
    "    return pd.DataFrame({\n",
    "        \"recommended_item\": [movies.get(model._rev_item_map.get(i, i), \"?\") for i in ids],\n",
    "        \"predicted_interest\": (scores / scores.max()).round(2),  # normalised 0-1\n",
    "        \"suggested_copy\": [\n",
    "            f\"Complete your order and we'll add '{movies.get(model._rev_item_map.get(i, i), '?')}' to your watchlist!\"\n",
    "            for i in ids\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# Abandoned cart: Romance + Thriller combo\n",
    "abandoned_cart = [181, 50]  # Return of the Jedi, Star Wars\n",
    "print(\"ðŸ›’ Abandoned cart:\")\n",
    "for ci in abandoned_cart:\n",
    "    print(f\"   {movies.get(ci, ci)}\")\n",
    "print(\"\\nðŸŽ¯ Recovery upsells:\")\n",
    "print(cart_abandonment_upsell(abandoned_cart).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Session Quality Score\n",
    "\n",
    "**How focused is this session?** When a user browses in a tight thematic cluster (all sci-fi, all documentaries), their intent is clear and conversion probability is high. We use the **self-consistency** of the session embedding to derive a quality score, which can be used to:\n",
    "- Trigger live-chat intervention for low-quality / scattered sessions\n",
    "- Prioritise high-quality sessions for personalised banners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_quality_score(session_item_ids: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Measures how coherent a session is by computing the mean pairwise\n",
    "    cosine similarity between item embeddings visited in this session.\n",
    "    Returns a score in [0, 1]; higher = more focused intent.\n",
    "    \"\"\"\n",
    "    encoded = [model._item_map[i] for i in session_item_ids if i in model._item_map]\n",
    "    if len(encoded) < 2:\n",
    "        return 0.0\n",
    "    embs = model._item_emb[np.array(encoded)]  # (n, d)\n",
    "    norms = np.linalg.norm(embs, axis=1, keepdims=True)\n",
    "    embs_n = embs / np.clip(norms, 1e-8, None)\n",
    "    sim_matrix = embs_n @ embs_n.T\n",
    "    # Mean of off-diagonal elements\n",
    "    n = len(encoded)\n",
    "    mean_sim = (sim_matrix.sum() - n) / (n * (n - 1)) if n > 1 else 0.0\n",
    "    return float(np.clip(mean_sim, 0, 1))\n",
    "\n",
    "# Compare a focused sci-fi session vs a scattered session\n",
    "sessions = {\n",
    "    \"Focused â€“ all Sci-Fi\": [50, 100, 258, 181, 1],     # Star Wars, Fargo, Contact, etc.\n",
    "    \"Scattered â€“ mixed genres\": [50, 475, 313, 29, 523], # very different films\n",
    "}\n",
    "\n",
    "for label, sess in sessions.items():\n",
    "    score = session_quality_score(sess)\n",
    "    intent = \"HIGH\" if score > 0.4 else (\"MEDIUM\" if score > 0.2 else \"LOW\")\n",
    "    print(f\"{label}\")\n",
    "    print(f\"  Quality score: {score:.3f}  â†’  Intent: {intent}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluating Recommendation Quality (Hit Rate @ 10)\n",
    "\n",
    "We run a quick leave-one-out evaluation to validate the model isn't just memorising training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EVAL = 200  # evaluate on 200 users for speed\n",
    "hits = 0\n",
    "\n",
    "for i, (ctx, truth) in enumerate(zip(train_seqs[:N_EVAL], val_truth[:N_EVAL])):\n",
    "    encoded = [model._item_map[x] for x in ctx if x in model._item_map]\n",
    "    if not encoded:\n",
    "        continue\n",
    "    rec_ids, _ = model.recommend_items(user_sequence=encoded, n=10, exclude=encoded)\n",
    "    decoded = {model._rev_item_map.get(r, r) for r in rec_ids}\n",
    "    if truth in decoded:\n",
    "        hits += 1\n",
    "\n",
    "hit_rate = hits / N_EVAL\n",
    "print(f\"Hit Rate @ 10 ({N_EVAL} users): {hit_rate:.2%}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  For {hit_rate:.0%} of users, the correct next item appears in our top-10 recommendations.\")\n",
    "print(\"  A random baseline would achieve ~0.5% (10 / 1682 items).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Business Summary\n",
    "\n",
    "| Capability | Code pattern | Business value |\n",
    "|---|---|---|\n",
    "| Anonymous-visitor recommendations | `model.recommend_items(encoded_session)` | Increases CTR for new visitors, no login required |\n",
    "| Re-engagement notification | Last N items â†’ top-1 recommendation | Lift in email open/click rates |\n",
    "| Cart abandonment recovery | Cart items â†’ next predicted item | Recovery revenue |\n",
    "| Session quality score | Mean pairwise cosine of visited items | Trigger intervention, prioritise high-intent sessions |\n",
    "| Leave-one-out eval | Context â†’ check if truth in top-K | Model monitoring / A/B test baseline |\n",
    "\n",
    "### When to use SASRec vs LightGCN\n",
    "\n",
    "| Scenario | Recommended model |\n",
    "|---|---|\n",
    "| Known user, long history | **LightGCN** â€” graph signals are richer |\n",
    "| New / anonymous visitor | **SASRec** â€” session context is all you have |\n",
    "| Physical store with POS sequences | **SASRec** â€” basket order encodes intent |\n",
    "| CRM-driven campaign scoring | **LightGCN** â€” scores the full user base at once |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
